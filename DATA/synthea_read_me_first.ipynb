{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee764803",
   "metadata": {},
   "source": [
    "# Pour obtenir les données de synthea : \n",
    "\n",
    "Étapes exactes\n",
    "\n",
    "0. Inutile de cloner le dépôt synthea !\n",
    "\n",
    "    ( Cela a déjà été fait dans un autre répertoire que celui de AURA, puis les références git ont été supprimées )\n",
    "\n",
    "    ( à l'origine ça venait de : git clone https://github.com/synthetichealth/synthea.git )\n",
    "\n",
    "\n",
    "1. se placer dans le bon répertoire :\n",
    "\n",
    "    cd synthea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae472007",
   "metadata": {},
   "source": [
    "2. Utiliser le Dockerfile dans ce dossier :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c56f31",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "FROM openjdk:11\n",
    "\n",
    "# Installer git et unzip\n",
    "RUN apt-get update && apt-get install -y git unzip && \\\n",
    "    apt-get clean && \\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copier le code synthea dans le conteneur\n",
    "COPY . /synthea\n",
    "WORKDIR /synthea\n",
    "\n",
    "# Rendre le script gradlew exécutable (au cas où)\n",
    "RUN chmod +x ./gradlew\n",
    "\n",
    "# Configurer les variables d'environnement pour Java/Gradle\n",
    "ENV GRADLE_OPTS=\"-Xmx2g -Xms1g -XX:MaxMetaspaceSize=512m\"\n",
    "ENV JAVA_OPTS=\"-Xmx4g -Xms2g -XX:+UseG1GC\"\n",
    "\n",
    "# Build du projet Java en sautant les tests pour éviter les problèmes de mémoire\n",
    "# Synthea est un générateur de données Java, les tests peuvent être lourds\n",
    "RUN ./gradlew build -x test --no-daemon --max-workers=1\n",
    "\n",
    "# Alternative avec tests (si vous avez assez de mémoire) :\n",
    "# RUN ./gradlew build --no-daemon --max-workers=1 -Dorg.gradle.jvmargs=\"-Xmx4g -Xms2g\"\n",
    "\n",
    "# Vérifier que le JAR a été créé\n",
    "RUN ls -la build/libs/\n",
    "\n",
    "# Générer les patients synthétiques au lancement\n",
    "# 1000 patients ça doit générer 1000000 observations, regroupées par la suite en 50000 lignes\n",
    "# 50 patients génère ? observations, regroupées en ? lignes\n",
    "CMD [\"java\", \"-jar\", \"build/libs/synthea-with-dependencies.jar\", \"-p\", \"50\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5683ef",
   "metadata": {},
   "source": [
    "Dans le dossier SYNTHEA/src/main/resources, modifier le fichier synthea.properties pour :\n",
    " \n",
    "   \n",
    "    exporter.fhir.export = true\n",
    "    exporter.csv.export = true\n",
    "    exporter.text.export = true\n",
    "    exporter.notes.fhir.export = true # ?? peut être que ça ne génère rien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dfae8",
   "metadata": {},
   "source": [
    "3. Construire l’image (va demander à télécharger JAVA) :\n",
    "\n",
    "    docker build -t synthea-100k-from-src .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea3fc9d",
   "metadata": {},
   "source": [
    "4. Lancer la génération vers ./GENERATED_FILES :\n",
    "\n",
    "    mkdir -p ../GENERATED_FILES\n",
    "\n",
    "    docker run --rm -v \"$(pwd)/../GENERATED_FILES\":/synthea/output synthea-100k-from-src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c3d03",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# première commande qui fonctionnait :\n",
    "# docker run --rm -v \"$(pwd)/../GENERATED_FILES\":/synthea/output synthea-100k-from-src\n",
    "\n",
    "\n",
    "# proposition de claude.ai : \n",
    "# docker run --rm -v \"$(pwd)/../GENERATED_FILES\":/synthea/output -v \"$(pwd)/src/main/resources/synthea.properties\":/synthea/src/main/resources/synthea.properties synthea-100k-from-src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1fa5129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire : /home/nicolascassonnet/Documents/WORK/aura-clinical-nlp/DATA\n",
      "Fichiers JSON : 56 = pas loin de 50\n",
      "Fichiers CSV : 18 = pas loin de 18\n"
     ]
    }
   ],
   "source": [
    "# Tester la présence des fichiers\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent = current_dir.parent\n",
    "\n",
    "data_dir : Path = None\n",
    "for path_info in parent.iterdir():\n",
    "    if path_info.is_dir() and path_info.name=='DATA' :\n",
    "        data_dir = path_info\n",
    "        break\n",
    "\n",
    "if data_dir != None :\n",
    "    print(f'Répertoire : {data_dir}')\n",
    "\n",
    "\n",
    "fhir_dir = Path(f'{data_dir}/GENERATED_FILES/fhir')\n",
    "fichiers_json = list(fhir_dir.glob('*.json'))\n",
    "print(f\"Fichiers JSON : {len(fichiers_json)} = pas loin de 50\")\n",
    "\n",
    "csv_dir = Path(f'{data_dir}/GENERATED_FILES/csv')\n",
    "fichiers_csv = list(csv_dir.glob('*.csv'))\n",
    "print(f\"Fichiers CSV : {len(fichiers_csv)} = pas loin de 18\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf439de",
   "metadata": {},
   "source": [
    "5. Générer un texte explicatif (en anglais) pour chaque observation\n",
    "\n",
    "    ... en cours : \n",
    "  \n",
    "    voir le fichier generate_annoted_csv.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2783e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "# def translate_fr_to_en(text_fr):\n",
    "#     result = translator(text_fr, max_length=512)\n",
    "#     return result[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac36c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from transformers import pipeline\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# # 1. Traduction\n",
    "# translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "# def translate_fr_to_en(text_fr):\n",
    "#     result = translator(text_fr, max_length=512)\n",
    "#     return result[0]['translation_text']\n",
    "\n",
    "# # 2. Charger Synthea\n",
    "# patients = pd.read_csv(\"synthea_output/csv/patients.csv\")\n",
    "# conditions = pd.read_csv(\"synthea_output/csv/conditions.csv\")\n",
    "# encounters = pd.read_csv(\"synthea_output/csv/encounters.csv\")\n",
    "\n",
    "# # 3. Préparer un texte descriptif par patient (concaténation conditions + encounters)\n",
    "# def get_patient_text(pid):\n",
    "#     conds = conditions[conditions['patient_id'] == pid]['description'].fillna('').str.cat(sep=' ')\n",
    "#     encs = encounters[encounters['patient_id'] == pid]['description'].fillna('').str.cat(sep=' ')\n",
    "#     return conds + ' ' + encs\n",
    "\n",
    "# patients['text_data'] = patients['id'].apply(get_patient_text)\n",
    "\n",
    "# # 4. Embeddings\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# patient_embeddings = model.encode(patients['text_data'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# def find_top_patients(text_en, top_k=3):\n",
    "#     query_emb = model.encode(text_en, convert_to_tensor=True)\n",
    "#     cos_scores = util.cos_sim(query_emb, patient_embeddings)[0]\n",
    "#     top_results = cos_scores.topk(k=top_k)\n",
    "#     return [(patients.iloc[idx]['id'], cos_scores[idx].item()) for idx in top_results.indices]\n",
    "\n",
    "# # 5. Utilisation\n",
    "# text_fr = \"Fièvre élevée, toux sèche, difficulté à respirer.\"\n",
    "# text_en = translate_fr_to_en(text_fr)\n",
    "\n",
    "# top_patients = find_top_patients(text_en)\n",
    "\n",
    "# for pid, score in top_patients:\n",
    "#     print(f\"Patient {pid} - Score similarité: {score:.3f}\")\n",
    "#     conds = conditions[conditions['patient_id'] == pid][['description', 'start_date', 'end_date']]\n",
    "#     print(\"Conditions associées :\")\n",
    "#     print(conds.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
