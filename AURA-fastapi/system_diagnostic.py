#!/usr/bin/env python3
"""
Script de diagnostic pour v√©rifier la compatibilit√© avec HiTZ/Medical-mT5-large
"""

import sys
import os
import platform
import psutil
import subprocess
import importlib
from pathlib import Path

def print_header(title):
    """Affiche un titre format√©"""
    print("\n" + "="*60)
    print(f" {title}")
    print("="*60)

def print_status(check, status, details=""):
    """Affiche le statut d'une v√©rification"""
    symbol = "‚úÖ" if status else "‚ùå"
    print(f"{symbol} {check}: {details}")

def check_python_version():
    """V√©rifie la version de Python"""
    print_header("VERSION PYTHON")
    version = sys.version_info
    is_compatible = version.major == 3 and version.minor >= 8
    print_status("Python version", is_compatible, 
                f"{version.major}.{version.minor}.{version.micro}")
    if not is_compatible:
        print("   ‚ö†Ô∏è  Python 3.8+ recommand√© pour Transformers")
    return is_compatible

def check_system_resources():
    """V√©rifie les ressources syst√®me"""
    print_header("RESSOURCES SYST√àME")
    
    # RAM
    memory = psutil.virtual_memory()
    ram_gb = memory.total / (1024**3)
    ram_available_gb = memory.available / (1024**3)
    ram_ok = ram_gb >= 8
    
    print_status("RAM totale", ram_ok, f"{ram_gb:.1f} GB")
    print_status("RAM disponible", ram_available_gb >= 4, f"{ram_available_gb:.1f} GB")
    
    # Espace disque
    disk = psutil.disk_usage('/')
    disk_free_gb = disk.free / (1024**3)
    disk_ok = disk_free_gb >= 5
    
    print_status("Espace disque libre", disk_ok, f"{disk_free_gb:.1f} GB")
    
    # CPU
    cpu_count = psutil.cpu_count()
    cpu_ok = cpu_count >= 2
    print_status("Processeurs", cpu_ok, f"{cpu_count} cores")
    
    # Syst√®me d'exploitation
    print_status("OS", True, f"{platform.system()} {platform.release()}")
    
    return ram_ok and disk_ok and cpu_ok

def check_required_packages():
    """V√©rifie les packages Python requis"""
    print_header("PACKAGES PYTHON")
    
    required_packages = {
        'torch': '2.0.0',
        'transformers': '4.21.0',
        'tokenizers': '0.13.0',
        'sentencepiece': '0.1.96',
        'protobuf': 'sourc',
        'numpy': '1.21.0'
    }
    
    all_ok = True
    
    for package, min_version in required_packages.items():
        try:
            module = importlib.import_module(package)
            version = getattr(module, '__version__', 'unknown')
            print_status(f"{package}", True, f"v{version}")
        except ImportError:
            print_status(f"{package}", False, "NON INSTALL√â")
            all_ok = False
    
    return all_ok

def check_huggingface_cache():
    """V√©rifie le cache Hugging Face"""
    print_header("CACHE HUGGING FACE")
    
    # R√©pertoire de cache par d√©faut
    cache_dir = Path.home() / '.cache' / 'huggingface'
    transformers_cache = cache_dir / 'hub'
    
    print(f"üìÅ R√©pertoire cache: {cache_dir}")
    print_status("Cache existe", cache_dir.exists())
    
    if cache_dir.exists():
        # Calculer la taille du cache
        total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())
        cache_size_gb = total_size / (1024**3)
        print_status("Taille du cache", True, f"{cache_size_gb:.2f} GB")
        
        # V√©rifier si le mod√®le est d√©j√† t√©l√©charg√©
        model_cache = transformers_cache / "models--HiTZ--Medical-mT5-large"
        model_cached = model_cache.exists()
        print_status("Medical-mT5-large en cache", model_cached)
        
        if model_cached:
            model_size = sum(f.stat().st_size for f in model_cache.rglob('*') if f.is_file())
            model_size_gb = model_size / (1024**3)
            print(f"   üì¶ Taille du mod√®le: {model_size_gb:.2f} GB")
    
    return True

def test_model_loading():
    """Test de chargement du mod√®le (optionnel)"""
    print_header("TEST DE CHARGEMENT (OPTIONNEL)")
    
    response = input("Voulez-vous tester le chargement du mod√®le ? (y/N): ").lower().strip()
    
    if response not in ['y', 'yes', 'oui']:
        print("‚è© Test de chargement ignor√©")
        return True
    
    print("üîÑ Tentative de chargement du mod√®le...")
    print("   (Cela peut prendre plusieurs minutes la premi√®re fois)")
    
    try:
        from transformers import AutoTokenizer, MT5ForConditionalGeneration
        
        model_name = "HiTZ/Medical-mT5-large"
        
        # Test tokenizer
        print("   üìù Chargement du tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        print_status("Tokenizer", True, "Charg√© avec succ√®s")
        
        # Test mod√®le
        print("   üß† Chargement du mod√®le...")
        model = MT5ForConditionalGeneration.from_pretrained(model_name)
        print_status("Mod√®le", True, "Charg√© avec succ√®s")
        
        # Test simple
        print("   üß™ Test de g√©n√©ration...")
        inputs = tokenizer("question: Qu'est-ce que la grippe ?", return_tensors="pt")
        outputs = model.generate(**inputs, max_length=50)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print_status("G√©n√©ration de texte", True, f"'{response[:50]}...'")
        
        return True
        
    except Exception as e:
        print_status("Test de chargement", False, str(e))
        return False

def check_internet_connection():
    """V√©rifie la connexion internet"""
    print_header("CONNEXION INTERNET")
    
    try:
        import urllib.request
        urllib.request.urlopen('https://huggingface.co', timeout=10)
        print_status("Connexion Hugging Face", True, "OK")
        return True
    except Exception as e:
        print_status("Connexion Hugging Face", False, str(e))
        return False

def generate_recommendations(results):
    """G√©n√®re des recommandations bas√©es sur les r√©sultats"""
    print_header("RECOMMANDATIONS")
    
    if not results['python']:
        print("üîß Mettez √† jour Python vers la version 3.8+")
    
    if not results['resources']:
        print("üîß Consid√©rez:")
        print("   - Fermer d'autres applications pour lib√©rer de la RAM")
        print("   - Lib√©rer de l'espace disque")
        print("   - Utiliser un mod√®le plus petit si les ressources sont limit√©es")
    
    if not results['packages']:
        print("üîß Installez les packages manquants:")
        print("   pip install -r requirements.txt")
    
    if not results['internet']:
        print("üîß V√©rifiez votre connexion internet pour t√©l√©charger les mod√®les")
    
    if all(results.values()):
        print("üéâ Votre syst√®me est pr√™t pour Medical-mT5-large !")
        print("üí° Vous pouvez maintenant utiliser le mod√®le en toute confiance.")

def main():
    """Fonction principale"""
    print("üîç DIAGNOSTIC SYST√àME POUR MEDICAL-MT5-LARGE")
    print("Ce script v√©rifie si votre machine peut ex√©cuter le mod√®le")
    
    # Ex√©cuter toutes les v√©rifications
    results = {
        'python': check_python_version(),
        'resources': check_system_resources(),
        'packages': check_required_packages(),
        'cache': check_huggingface_cache(),
        'internet': check_internet_connection()
    }
    
    # Test optionnel du mod√®le
    results['model_test'] = test_model_loading()
    
    # R√©sum√©
    print_header("R√âSUM√â")
    total_checks = len([k for k in results.keys() if k != 'model_test'])
    passed_checks = sum([1 for k, v in results.items() if v and k != 'model_test'])
    
    print(f"üìä V√©rifications r√©ussies: {passed_checks}/{total_checks}")
    
    if passed_checks == total_checks:
        print("‚úÖ Votre syst√®me est compatible !")
    else:
        print("‚ö†Ô∏è  Quelques ajustements sont n√©cessaires")
    
    # G√©n√©rer les recommandations
    generate_recommendations(results)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Diagnostic interrompu par l'utilisateur")
    except Exception as e:
        print(f"\n‚ùå Erreur durant le diagnostic: {e}")
        print("Veuillez v√©rifier que toutes les d√©pendances sont install√©es")